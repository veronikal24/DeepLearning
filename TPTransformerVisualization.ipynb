{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8cd5aa2",
   "metadata": {},
   "source": [
    "# Visualization of Transformer Prediction on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b1d4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tptrans import TPTrans\n",
    "from dataloader import load_parquet, preprocess_data, SlidingWindowDataset\n",
    "from plotting import plot_testresult_sample\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca442887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in your case it will be\n",
    "#dataset = \"dataset\"\n",
    "dataset = \"aisdk-2025-02-27\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d97449",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "listdir: path should be string, bytes, os.PathLike, integer or None, not SlidingWindowDataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mload_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m preprocess_data(df)\n\u001b[1;32m      4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m SlidingWindowDataset(\n\u001b[1;32m      5\u001b[0m     df,\n\u001b[1;32m      6\u001b[0m     max_diff_per_sequence_minutes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m~/DeepLearning-1/dataloader.py:134\u001b[0m, in \u001b[0;36mload_parquet\u001b[0;34m(parquet_dir, k, seed)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m\"\"\"Loads a randomized sample of the previously created parquet files from the given directory.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    pandas.dataframe: pandas dataframe of the loaded data (downsampled to 6 minute intervals)\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# List all MMSI directories\u001b[39;00m\n\u001b[1;32m    132\u001b[0m mmsi_dirs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m    133\u001b[0m     d\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparquet_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(parquet_dir, d))\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mmsi_dirs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo MMSI partitions found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: listdir: path should be string, bytes, os.PathLike, integer or None, not SlidingWindowDataset"
     ]
    }
   ],
   "source": [
    "df = load_parquet(dataset, k=5)\n",
    "df = preprocess_data(df)\n",
    "\n",
    "dataset = SlidingWindowDataset(\n",
    "    df,\n",
    "    max_diff_per_sequence_minutes=15,\n",
    "    window_size_minutes=120,\n",
    "    pred_size_minutes=30,\n",
    "    stride=15,\n",
    ")\n",
    "test_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = TPTrans(pred_len=dataset[0][1].shape[0]).to(device)\n",
    "model.load_state_dict(torch.load(\"checkpoints/tptrans_delta_lin_newNewParams_175.pth\", map_location=torch.device(device)))\n",
    "#model.load_state_dict(torch.load(\"/zhome/63/7/219953/DeepLearning-1/checkpoints/tpinformer_delta_lin_newNewParams_375.pth\", map_location=torch.device(device)))\n",
    "model.eval()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "test_loss = 0.0\n",
    "data = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        tgt_start = x[:, -1:, :2]  # (batch, 1, 2) lat/lon\n",
    "        pred = model(x, tgt_start)\n",
    "        data.append((x,y,pred))\n",
    "        loss = criterion(pred, y)\n",
    "        test_loss += loss.item() * x.size(0)\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print(f\"Test Loss: {test_loss:.6f}\", flush=True)\n",
    "\n",
    "plot_testresult_sample(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
