{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a70970c4",
   "metadata": {},
   "source": [
    "# Visualized Performanced of the Modified Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82a2a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tpinform_experiment import TPTrans, PositionalEncoding\n",
    "from dataloader import load_parquet, preprocess_data, SlidingWindowDataset\n",
    "from plotting import plot_testresult_sample\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81031513",
   "metadata": {},
   "source": [
    "## Short Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b8dfab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zhome/63/7/219953/DeepLearning-1/dataloader.py:167: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df.set_index(\"Timestamp\")\n",
      "/zhome/63/7/219953/DeepLearning-1/dataloader.py:167: FutureWarning: DataFrameGroupBy.resample operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.set_index(\"Timestamp\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of windows: 12\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TPTrans' object has no attribute 'decoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# don’t pass tgt_start, your current forward() doesn’t use it\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m data\u001b[38;5;241m.\u001b[39mappend((x, y, pred))\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# if you trained on coordinates, be consistent:\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# loss = criterion(deltas_to_coords(x, pred), deltas_to_coords(x, y))\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/DeepLearning-1/tpinform_experiment.py:175\u001b[0m, in \u001b[0;36mTPTrans.forward\u001b[0;34m(self, src, pred_len)\u001b[0m\n\u001b[1;32m    171\u001b[0m tgt \u001b[38;5;241m=\u001b[39m tgt_pe\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# (batch, pred_len, d_model)\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Informer-style decoder call:\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# decoder(x=tgt, cross=memory, x_mask=None, cross_mask=None)\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m dec_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m(\n\u001b[1;32m    176\u001b[0m     tgt,\n\u001b[1;32m    177\u001b[0m     memory,\n\u001b[1;32m    178\u001b[0m     x_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    179\u001b[0m     cross_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    180\u001b[0m )  \u001b[38;5;66;03m# (batch, pred_len, d_model)\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# project to (delta_lat, delta_lon)\u001b[39;00m\n\u001b[1;32m    183\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj(dec_out)  \u001b[38;5;66;03m# (batch, pred_len, 2)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1962\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1960\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1961\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1962\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1963\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1964\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TPTrans' object has no attribute 'decoder'"
     ]
    }
   ],
   "source": [
    "df = load_parquet(\"dataset\", k=5)\n",
    "df = preprocess_data(df)\n",
    "\n",
    "dataset = SlidingWindowDataset(\n",
    "    df,\n",
    "    max_diff_per_sequence_minutes=15,\n",
    "    window_size_minutes=120,\n",
    "    pred_size_minutes=30,\n",
    "    stride=15,\n",
    ")\n",
    "print(\"Number of windows:\", len(dataset))\n",
    "test_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torch.load(\n",
    "    \"checkpoints/t_1500_400_20_420_120_15_64_0.0005.pth\",\n",
    "    map_location=device,\n",
    "    weights_only=False\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "test_loss = 0.0\n",
    "data = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # don’t pass tgt_start, your current forward() doesn’t use it\n",
    "        pred = model(x)\n",
    "\n",
    "        data.append((x, y, pred))\n",
    "\n",
    "        # if you trained on coordinates, be consistent:\n",
    "        # loss = criterion(deltas_to_coords(x, pred), deltas_to_coords(x, y))\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "        test_loss += loss.item() * x.size(0)\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print(f\"Test Loss: {test_loss:.6f}\", flush=True)\n",
    "\n",
    "plot_testresult_sample(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
